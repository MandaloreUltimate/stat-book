\section{Статистическая структура. Выборка. Статистика. Порядковые статистики. Вариационный ряд. Эмпирическая функция распределения}

\begin{defn}
    \textit{Статистическая структура}~--- совокупность $(\Real^n, \Borel^n, \Dist_\theta)$, 
    где $\Real^n$~--- выборочное пространство, 
    $\Borel^{n}$~--- борелевская $\sigma$-алгебра на $\Real^n$, $\Dist_\theta$~--- семейство распределений, 
    определённых на $\Borel^n$, параметризованное одно- или многомерным числовым параметром: 
    $\Dist_\theta = (\MyPr{\theta} \colon \theta \in \Theta \subseteq R^{m})$.
\end{defn}

\begin{defn}
    \textit{Выборка} $\SampleX= \Sample$ объёма $n$~--- набор из $n$ независимых и одинаково распределённых случайных величин\footnote{Вообще говоря, в приложениях возникают также выборки, состоящие из зависимых или разнораспределённых элементов, но изучение их свойств не входит в этот курс.}, имеющих такое же распределение, как и наблюдаемая случайная величина $\xi$.
\end{defn}

До того, как эксперимент проведён, выборка~--- набор случайных величин, после~--- набор чисел из множества возможных значений случайной величины. 
Числовой набор $\boldsymbol{x} = (x_1, \ldots, x_n)$ будем называть \textit{реализацией выборки}.

\begin{rmrk}
    Статистическая структура очень похожа на многомерное \hyperlink{induced_prob_space}{\textit{индуцированное вероятностное пространство}}.
    Отличие заключается в том, что если ранее мы использовали распределение лишь одной случайной величины~$\xi$, то здесь используется целое семейство.
    Почему?
    Дело в том, что мы ещё не знаем, каковы параметры исследуемого распределения.
    Задача математической статистики как раз и заключается в том, чтобы их найти, основываясь на наблюдениях~--- реализациях выборок.

    Отметим также то, что в различных источниках $\Dist_\theta$ может называться семейством \textit{вероятностных мер}.
    Это тоже верно, но может внести путаницу~--- распределение случайной величины действительно является мерой, определённой на борелевской $\sigma$-алгебре.
    Однако вероятностная мера, вообще говоря, не связана ни с какой случайной величиной~--- это просто отображение из некоторой $\sigma$-алгебры событий в вещественные числа, удовлетворяющее аксиомам неотрицательности, ограниченности и счётной аддитивности.
    А распределение случайной величины~--- это композиция прообраза и вероятностной меры: $P_{\xi} = \MyPr \circ \xi^{-1}$.
    Т.е. распределение содержит информацию о конкретной случайной величине, с некоторыми фиксированными параметрами.
    Именно поэтому мы используем семейство распределений.
    Нам не нужно много вероятностных мер~--- нам нужно много распределений с разными наборами параметров.

    Следует обратить внимание на то, что поскольку распределение зависит от параметра $\theta$, то от него будут зависеть и математическое ожидание, и дисперсия, и прочие числовые характеристики налюдаемой случайной величины.
    Например, для "<честной"> монетки математическое ожидание при 10 подбрасываниях должно быть равно 5, а дисперсия~--- $npq = 10 \cdot \frac{1}{2} \cdot \frac{1}{2} = 2.5$. 
    Но в случае асимметричной монетки с вероятностью выпадения "<решки">, равной $0.7$, математическое ожидание будет равно 7, а дисперсия~--- $2.1$.
    Поэтому лучше явно указывать зависимость от параметра и писать $\MyPrTh\,, \ExpTh, \VarTh$.
\end{rmrk}

\begin{defn}
    \textit{Статистика} или \textit{оценка}~--- измеримая функция от выборки, не зависящая от любых других параметров. Чаще всего статистики используются для поиска неизвестного параметра распределения $\theta$ и имеют вид $T\colon \Real^n \mapsto \Theta$.
\end{defn}

\begin{defn}
    \textit{Вариационный ряд}~--- набор случайных величин $X_{(1)}, \ldots, X_{(n)}$, который получается при упорядочении выборки $\SampleX= \Sample$ по возрастанию на каждом элементарном исходе. 

    $X_{(1)}(\omega)=\min \bigl(X_{1}(\omega), \ldots, X_{n}(\omega)\bigr)$~--- \textit{минимальная порядковая статистика}, 
    $X_{(n)}(\omega)=\max \bigl(X_{1}(\omega), \ldots, X_{n}(\omega)\bigr)$~--- соответственно, \textit{максимальная}.
    Элемент $X_{(k)}$~--- \textit{$k$-я порядковая статистика}. 
\end{defn}

\begin{rmrk}
    Согласно нашему определению, вариационный ряд \textit{не является выборкой}, хотя бы потому, что разные порядковые статистики, как мы вскоре убедимся, имеют разное распределение.
    Однако он является статистикой $T\colon \Real^n \mapsto \Real^n$, так как зависит только от выборки\footnote{Конечно, формально ещё необходимо проверить на измеримость функцию, осуществляющую переупорядочение}.
    Порядковые статистики тоже удовлетворяют определению статистики, но являются уже отображениями из $\Real^n$ в $\Real$.
\end{rmrk}

\begin{defn}
    \textit{Эмпирическая функция распределения}, построенная по выборке $X_{1}, \ldots, X_{n}$ объёма $n$,~--- случайная функция $F_{n}^{*}$:
    \begin{equation*}
        F_{n}^{*}(y) =\frac{1}{n} \sum\limits_{i=1}^{n} \Ind(X_{i}<y) \quad \forall y \in \Real
    \end{equation*}
\end{defn}

Эмпирическая функция распределения строится по вариационному ряду следующим образом:

\begin{equation*}
    F_{n}^{*}(y)=\left\{\begin{array}{ll}
    0,   & y \leqslant X_{(1)} \\
    k/n, & X_{(k)} < y \leqslant X_{(k+1)} \\
    1,   & y > X_{(n)}
    \end{array}\right.
\end{equation*}

\begin{exmp}
    Найдём эмпирические функции распределения для крайних порядковых статистик.
    \begin{gather*}
        \begin{aligned}
            F_{(1)}(x)=\MyPrTh \bigl(X_{(1)} < x \bigr) 
        = 1 - \MyPrTh \bigl(X_{(1)} \geqslant x \bigr) 
        = 1 - \MyPrTh \bigl(x_{1} \geqslant x, \ldots, x_{n} \geqslant x\bigr) = \\
        = 1 - \prod_{i=1}^{n} \MyPrTh (x_{i} \geqslant x) 
        = 1 - \bigl(\MyPrTh ({x}_{1} \geqslant x)\bigr)^{n} 
        = 1 - \bigl(1 - F_{\theta}(x)\bigr)^{n}\!.
        \end{aligned} \\
        \begin{aligned}
            F_{(n)}(x) 
            = \MyPrTh \bigl(X_{(n)} < x\bigr) 
            = \MyPrTh \bigl(x_{1} < x, \ldots, x_{n} < x\bigr) = \\
            = \prod_{i=1}^{n} \MyPrTh (x_{i} < x) 
            = \bigl(\MyPrTh ({x}_{1} < x)\bigr)^{n} 
            = \bigl( F_{\theta}(x) \bigr)^n \!.
        \end{aligned}
    \end{gather*}
\end{exmp}

\begin{namedthm}[Свойства эмпирической функции распределения]\leavevmode
    \begin{enumerate}
        \item Пусть $\Sample$~--- выборка из семейства распределений $\Dist_{\theta}$ с функцией распределения $F_{\theta}$ и пусть $F_{n}^{*}$ — эмпирическая функция распределения, построенная по этой выборке. 
        Тогда $F_{n}^{*}(y) \xrightarrow[n \to \infty]{\text{p}} F_{\theta}(y)$ для любого $y \in \Real$ и $\AllTh.$
        \item Для любого y $\in \Real$ и любого $\theta \in \Theta$:
        \begin{enumerate}[label={\arabic*)}]
            \item $\ExpTh F_{n}^{*}(y) = F_{\theta}(y)$, т.е. $F_{n}^{*}(y)$~--- несмещённая оценка для $F_{\theta}(y)$.
            \item $\VarTh F_{n}^{*}(y)=\cfrac{F_{\theta}(y)\bigl(1-F_{\theta}(y)\bigr)}{n} \: \leqslant \: \cfrac{1}{4n}$\, .
            \item Пусть $\sigma^2(y) = \bigl(1 - F_{\theta}(y)\bigr)F_{\theta}(y)$. 
            Тогда
            \begin{equation*}
                \sqrt{n}\bigl( F_{n}^{*}(y)-F_{\theta}(y) \bigr) \; \xrightarrow[n \to \infty]{\text{d}} \; \Normal_{0, \sigma^2(y)},
            \end{equation*}
            т.е. $F_{n}^{*}(y)$~--- асимптотически нормальная оценка для $F_{\theta}(y)$.
            \item $n F_{n}^{*}(y) \sim \Binom_{n, F_{\theta}(y)}.$
            \item $F_{n}^{*}(y) \xrightarrow[n \to \infty]{\text{п.н.}} F_{\theta}(y).$
        \end{enumerate}
    \end{enumerate}
\end{namedthm}

\begin{proof}\leavevmode
    \begin{enumerate}
        \item 
            $F_{n}^{*}(y)=\frac{1}{n} \sum\limits_{i=1}^{n} \Ind(X_{i}<y)$, при этом случайные величины $\Ind(X_{1}<y)$, $\Ind(X_{2}<y), \ldots$ независимы и одинаково распределены, их математическое ожидание конечно:
            \begin{equation*}
                \ExpTh \Ind(X_{1}<y)=1 \cdot \MyPrTh (X_{1}<y)+0 \cdot \MyPrTh (X_{1} \geqslant y) = \MyPrTh (X_{1}<y)=F_{\theta}(y) < \infty
            \end{equation*}
            Следовательно, можно применить ЗБЧ в форме Хинчина:
            \begin{equation*}
                F_{n}^{*}(y)=\cfrac{\sum\limits_{i=1}^{n} \Ind(X_{i}<y)}{n} \xrightarrow[n \to \infty]{\text{p}} \ExpTh \Ind(X_{1}<y)=F_{\theta}(y) \quad \AllTh.
            \end{equation*}
        \item 
            Заметим:
            \begin{gather*}
                \Ind(X_{1}<y) \sim  \Binom_{1, F_{\theta}(y)} \implies \ExpTh \Ind(X_{1}<y) = F_{\theta}(y), \\
                \VarTh \Ind(X_{1}<y) = F_{\theta}(y)(1-F_{\theta}(y)) \quad \AllTh.
            \end{gather*}
            \begin{enumerate}[label={\arabic*)}]
                \item Случайные величины $\Ind(X_{i}<y)$ одинаково распределены, поэтому:
                \begin{equation*}
                    \ExpTh F_{n}^{*}(y) = \ExpTh \, \cfrac{\sum\limits_{i=1}^{n} \Ind(X_{i}<y)}{n} =\cfrac{\sum\limits_{i=1}^{n} \ExpTh \Ind(X_{i}<y)}{n}=\cfrac{n \ExpTh \Ind(X_{1}<y)}{n}=F_{\theta}(y)  
                \end{equation*}
                
                \item Случайные величины $\Ind(X_{i}<y)$ независимы и одинаково распределены, поэтому:
                \begin{multline*}
                    \VarTh F_{n}^{*}(y)
                    = \VarTh \, \cfrac{\sum\limits_{i=1}^{n} \Ind(X_{i}<y)}{n}
                    = \cfrac{\sum\limits_{i=1}^{n} \VarTh \Ind(X_{i}<y)}{n^{2}}
                    = \\
                    = \cfrac{n\VarTh \Ind(X_{1}<y)}{n^{2}}
                    = \cfrac{F_{\theta}(y)\bigl(1-F_{\theta}(y)\bigr)}{n}
                \end{multline*}
                Значения $F_{\theta}(y)$ принадлежат отрезку $[0, 1]$, а значит, произведение $F_{\theta}(y)\bigl(1 - F_{\theta}(y)\bigr) \leqslant \cfrac{1}{2}\cdot\left(1 - \cfrac{1}{2}\right) = \cfrac{1}{4}~$ (нетрудно убедиться, что 1/2~--- точка максимума). 
                А значит, $\VarTh F_{n}^{*} \leqslant \cfrac{1}{4n}\,$. 
            \end{enumerate}
        \item 
            Применим ЦПТ:
            \begin{multline*}
                \sqrt{n}\bigl( F_{n}^{*}(y)-F_{\theta}(y) \bigr)
                = \sqrt{n}\left(\cfrac{\sum \Ind(X_{i}<y)}{n}-F_{\theta}(y)\right) 
                = \\
                = \cfrac{\sum\limits_{i=1}^{n} \Ind(X_{i}<y)-n F_{\theta}(y)}{\sqrt{n}} 
                = \cfrac{\sum\limits_{i=1}^{n} \Ind(X_{i}<y)-n \ExpTh\Ind(X_{1}<y)}{\sqrt{n}} 
                \xrightarrow[n \to \infty]{\text{d}} \\
                \xrightarrow[n \to \infty]{\text{d}} \Normal_{0, \VarTh\Ind(X_{1}<y)}
                = \Normal_{0, (1-F_{\theta}(y))F_{\theta}(y)}.
            \end{multline*}
        \item 
            Следует из устойчивости по суммированию биномиального распределения. 
            Поскольку $\Ind\left(X_{i}<y\right)$ независимы и имеют биномиальное распределение $\Binom_{1, F_{\theta}(y})$, то их сумма
            \begin{equation*}
                n F_{n}^{*}(y)=\Ind\left(X_{1}<y\right)+\ldots+\Ind\left(X_{n}<y\right)
            \end{equation*}
            имеет биномиальное распределение $\Binom_{n, F_{\theta}(y})$.
            
        \item 
            Выберем произвольный $y \in \Real$. 
            $\xi_i = \Ind(X_i < y)$ независимы, одинаково распределены и $\exists \ExpTh \xi_i = F_{\theta}(y)$.
            Тогда можно применить \hyperlink{SLLN}{усиленный закон больших чисел в форме Колмогорова}: ${\MyPrTh\left(\lim\limits_{n \to \infty} \frac{1}{n} \sum\limits_{i = 1}^{n}\xi_i = F_{\theta}(y)\right) = 1} \; \AllTh$, что является непосредственным определением сходимости эмпирической функции распределения почти наверное к теоретической.
    \end{enumerate}  
\end{proof}
